# 转载：2025 我最喜欢的 LLM x AI 论文集


## 2025 我最喜欢的 LLM x AI 论文集

2025年快过去了。

这一年，我几乎每天都有坚持读论文和分享论文， 获益匪浅。

下面是我整理的个人年度最喜欢论文集：

### 1、Test Time Scaling

- “Thinking” 到底是什么？

##### [DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via Reinforcement Learning](https://arxiv.org/pdf/2501.12948)

##### [s1: Simple test-time scaling](https://arxiv.org/pdf/2501.19393) 



### 2. Efficient Reasoning

- “如果思考一种budget”

##### [L1: Controlling How Long A Reasoning Model Thinks With Reinforcement Learning](https://arxiv.org/pdf/2503.04697)

##### [Scalable Chain of Thoughts via Elastic Reasoning](https://arxiv.org/pdf/2505.05315)



### 3. Reasoning Analysis

- 该如何更好理解 “Reasoning” ？

##### [(How) Do reasoning models reason?](https://arxiv.org/pdf/2504.09762)

##### [DeepSeek-R1 Thoughtology: Let’s about LLM reasoning](https://arxiv.org/pdf/2504.07128)

##### [Rethinking Reflection in Pre-Training](https://arxiv.org/pdf/2504.04022)

##### [Thinking vs. Doing: Agents that Reason by Scaling Test-Time Interaction](arxiv.org/pdf/2506.07976)



### 4. CLI Agent

- 2024年文章，但深度影响了2025。

##### [SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering](https://arxiv.org/pdf/2405.15793)



### 5. LLM X RL Agentic

- 为此，我创造了一个词，“协议token”

##### [ReTool: Reinforcement Learning for Strategic Tool Use in LLMs](https://arxiv.org/pdf/2504.11536)

##### [ReSearch: Learning to Reason with Search for LLMs via Reinforcement Learning](https://arxiv.org/pdf/2503.19470)

##### [ReCall: Learning to Reason with Tool Call for LLMs via Reinforcement Learning](https://attractive-almandine-935.notion.site/ReCall-Learning-to-Reason-with-Tool-Call-for-LLMs-via-Reinforcement-Learning-1d7aec91e9bb8006ad40f9edbfe2191a)



### 6. Parallel Reasoning

- 并行 reasoning，超越单线程的想象！

##### [Learning Adaptive Parallel Reasoning with Language Models](https://arxiv.org/pdf/2504.15466)

##### [Multiverse: Your Language Models Secretly Decide How to Parallelize and Merge Generation](https://arxiv.org/pdf/2506.09991)

##### [Learning to Keep a Promise: Scaling Language Model Decoding Parallelism with Learned Asynchronous Decoding](https://arxiv.org/pdf/2502.11517)



### 7. RL X Reasoning,

- RLVR 这四篇，给 RL X Reasoning 极速升温+降温！

##### [Reinforcement Learning for Reasoning in Large Language Models with One Training Example](https://arxiv.org/pdf/2504.20571)

##### [Absolute Zero: Reinforced Self-play Reasoning with Zero Data](https://arxiv.org/pdf/2505.03335)

##### [Learning to Reason without External Rewards](https://arxiv.org/pdf/2505.19590)

##### [Spurious Rewards: Rethinking Training Signals in RLVR](https://arxiv.org/pdf/2506.10947)



### 8. Agent, interaction Deep research agent

- 经验，记忆，交互，workflow，围绕

##### [Agent KB: Leveraging Cross-Domain Experience for Agentic Problem Solving](https://arxiv.org/pdf/2507.06229)

##### [Alita-G: Self-Evolving Generative Agent for Agent Generation](https://arxiv.org/pdf/2510.23601)

##### [Sleep-time Compute: Beyond Inference Scaling at Test-time](https://arxiv.org/pdf/2504.13171)

##### [WebThinker: Empowering Large Reasoning Models with Deep Research Capability](https://arxiv.org/pdf/2504.21776)

##### [WebDancer: Towards Autonomous Information Seeking Agency](https://arxiv.org/pdf/2505.22648)



### 9. Risk modeling X LLM

- “让贝叶斯再次伟大！”

##### [Model Predictive Task Sampling for Efficient and Robust Adaptation](https://arxiv.org/pdf/2501.11039)

##### [Can Prompt Difficulty be Online Predicted for Accelerating RL Finetuning of Reasoning Models?](https://arxiv.org/pdf/2507.04632)



### 10. Multi-Agentic

- Multi Agent该怎么用？

##### [Co-Evolving LLM Coder and Unit Tester via Reinforcement Learning](https://arxiv.org/pdf/2506.03136)

##### [CodeContests+: High-Quality Test Case Generation for Competitive Programming](https://arxiv.org/pdf/2506.05817)



### 11. Sentient Agent

- AI + 人文，情怀满满！

##### [RLVER: Reinforcement Learning with Verifiable Emotion Rewards for Empathetic Agents](https://arxiv.org/pdf/2507.03112)

##### [Sentient Agent as a Judge: Evaluating Higher-Order Social Cognition in Large Language Models](https://arxiv.org/pdf/2505.02847)



### 12: LLM security and alignment

- 想要懂你真的不容易, LLM!

##### [Chain of Thought Monitorability: A New and Fragile Opportunity for AI Safety](https://arxiv.org/pdf/2507.11473)

##### [Emergent Misalignment: Narrow finetuning can produce broadly misaligned LLMs](https://arxiv.org/pdf/2502.17424)

##### [Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models](https://arxiv.org/pdf/2506.13206)

##### [Natural Emergent Misalignment from Reward Hacking in Production RL](https://arxiv.org/pdf/2511.18397)

##### [Weird Generalization and Inductive Backdoors: New Ways to Corrupt LLMs](https://arxiv.org/pdf/2512.09742)



### 13. Model Steering

- 我要控制我自己，LLM!

##### [AxBench: Steering LLMs? Even Simple Baselines Outperform Sparse Autoencoders](https://arxiv.org/pdf/2501.17148)

##### [Persona Vectors: Monitoring and Controlling Character Traits in Language Models](https://arxiv.org/abs/2507.21509)

##### [How to Train Your Advisor: Steering Black-Box LLMs with Advisor Models](https://arxiv.org/abs/2510.02453)



最后，这个 list 是我的个人选择，因为时间精力有限，很多很好的工作，或许我都没有机会读到，感谢论文的作者们，带我领略智慧的风光！



2025年快过去了，我很怀念它！


2026年，会继续每天把我看到的最优秀的工作介绍给大家，很多深度的分析会专门放在订阅内容中，欢迎你成为我的订阅用户，我们一起成长！

###### 转载原文链接：[2025 我最喜欢的 LLM x AI 论文集](https://x.com/dongxi_nlp/status/2003574127211479442)




