<!doctype html><html lang=zh-CN><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>转载：2025 LLM 年度回顾 - SincereCSL's Blog</title><meta name=Description content="Simon Willison 年度回顾：2025年 LLM 领域发生的一切"><meta property="og:url" content="https://sincerecsl.github.io/theyearinllms/"><meta property="og:site_name" content="SincereCSL's Blog"><meta property="og:title" content="转载：2025 LLM 年度回顾"><meta property="og:description" content="Simon Willison 年度回顾：2025年 LLM 领域发生的一切"><meta property="og:locale" content="zh_CN"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2026-01-30T10:30:00+08:00"><meta property="article:modified_time" content="2026-01-30T10:30:00+08:00"><meta property="article:tag" content="LLM"><meta property="article:tag" content="AI"><meta property="article:tag" content="年度回顾"><meta property="article:tag" content="Claude"><meta property="article:tag" content="GPT"><meta property="article:tag" content="Gemini"><meta name=twitter:card content="summary"><meta name=twitter:title content="转载：2025 LLM 年度回顾"><meta name=twitter:description content="Simon Willison 年度回顾：2025年 LLM 领域发生的一切"><meta name=twitter:site content="@SincereCSL95"><meta name=application-name content="LoveIt"><meta name=apple-mobile-web-app-title content="LoveIt"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://sincerecsl.github.io/theyearinllms/><link rel=prev href=https://sincerecsl.github.io/mcpvsskills/><link rel=next href=https://sincerecsl.github.io/remotework/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=/lib/fontawesome-free/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/fontawesome-free/all.min.css></noscript><link rel=preload href=/lib/animate/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=/lib/animate/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"转载：2025 LLM 年度回顾","inLanguage":"zh-CN","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/sincerecsl.github.io\/theyearinllms\/"},"genre":"posts","keywords":"LLM, AI, 年度回顾, Claude, GPT, Gemini, DeepSeek","wordcount":5857,"url":"https:\/\/sincerecsl.github.io\/theyearinllms\/","datePublished":"2026-01-30T10:30:00+08:00","dateModified":"2026-01-30T10:30:00+08:00","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"SincereCSL"},"description":"Simon Willison 年度回顾：2025年 LLM 领域发生的一切"}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper style=position:relative><link href="https://fonts.googleapis.com/css2?family=Ma+Shan+Zheng&family=Orbitron:wght@500;700&display=swap" rel=stylesheet><script>function updateClock(){const e=new Date,s=e.getFullYear(),o=e.getMonth()+1,i=e.getDate(),n=`${s}年${o}月${i}日`,t=document.getElementById("clock-date");t&&t.innerText!==n&&(t.innerText=n);const a=String(e.getHours()).padStart(2,"0"),r=String(e.getMinutes()).padStart(2,"0"),c=String(e.getSeconds()).padStart(2,"0");updateFlipDigit("hour",a),updateFlipDigit("min",r),updateFlipDigit("sec",c)}function updateFlipDigit(e,t){const n=document.getElementById(`flip-${e}`);if(!n)return;const s=n.getAttribute("data-val");if(s!==t){n.setAttribute("data-val",t),n.classList.remove("flip-animate"),void n.offsetWidth,n.classList.add("flip-animate");const e=n.querySelector(".flip-curr"),o=n.querySelector(".flip-next");e&&(e.innerText=s||t),o&&(o.innerText=t),setTimeout(()=>{e&&(e.innerText=t),n.classList.remove("flip-animate")},500)}}setInterval(updateClock,1e3),window.addEventListener("DOMContentLoaded",updateClock)</script><div class=header-title><a href=/ title="SincereCSL's Blog"><span class=header-title-pre><i class='far fa-grin-stars fa-fw'></i></span>SincereCSL</a></div><div class=menu><div class=menu-inner><a class=menu-item href=/>主页 </a><a class=menu-item href=/posts/>所有文章 </a><a class=menu-item href=/links/>Links </a><a class=menu-item href=/categories/>分类 </a><a class=menu-item href=/about/>关于 </a><a class=menu-item href=https://github.com/SincereCSL rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i> </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder=搜索文章标题或内容... id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=搜索><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=清空><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a><div class=header-clock id=header-clock-desktop><div class=clock-date id=clock-date></div><div class=clock-time><div class=flip-unit id=flip-hour><span class=flip-curr>00</span><span class=flip-next>00</span></div><span class=flip-sep>:</span><div class=flip-unit id=flip-min><span class=flip-curr>00</span><span class=flip-next>00</span></div><span class=flip-sep>:</span><div class=flip-unit id=flip-sec><span class=flip-curr>00</span><span class=flip-next>00</span></div></div></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title="SincereCSL's Blog"><span class=header-title-pre><i class='far fa-grin-stars fa-fw'></i></span>SincereCSL</a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder=搜索文章标题或内容... id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=搜索><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=清空><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>取消</a></div><a class=menu-item href=/ title>主页</a><a class=menu-item href=/posts/ title>所有文章</a><a class=menu-item href=/links/ title>Links</a><a class=menu-item href=/categories/ title>分类</a><a class=menu-item href=/about/ title>关于</a><a class=menu-item href=https://github.com/SincereCSL title rel="noopener noreffer" target=_blank><i class='fab fa-github fa-fw'></i></a><a href=javascript:void(0); class="menu-item theme-switch" title=切换主题>
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class=post-layout><article class="page single"><h1 class="single-title animate__animated animate__flipInX">转载：2025 LLM 年度回顾</h1><div class=post-meta><div class=post-meta-line><span class=post-author><a href=/ title=Author rel=author class=author><i class="fas fa-user-circle fa-fw" aria-hidden=true></i>SincereCSL</a></span>&nbsp;<span class=post-category>收录于 <a href=/categories/llm-study/><i class="far fa-folder fa-fw" aria-hidden=true></i>LLM Study</a>&nbsp;<a href=/categories/ai-study/><i class="far fa-folder fa-fw" aria-hidden=true></i>AI Study</a></span></div><div class=post-meta-line><i class="far fa-calendar-alt fa-fw" aria-hidden=true></i>&nbsp;<time datetime=2026-01-30>2026-01-30</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden=true></i>&nbsp;约 5857 字&nbsp;
<i class="far fa-clock fa-fw" aria-hidden=true></i>&nbsp;预计阅读 12 分钟&nbsp;<span id=/theyearinllms/ class=leancloud_visitors data-flag-title="转载：2025 LLM 年度回顾">
<i class="far fa-eye fa-fw" aria-hidden=true></i>&nbsp;<span class=leancloud-visitors-count></span>&nbsp;次阅读
</span>&nbsp;</div></div><div class="details toc" id=toc-static data-kept><div class="details-summary toc-title"><span>目录</span>
<span><i class="details-icon fas fa-angle-right" aria-hidden=true></i></span></div><div class="details-content toc-content" id=toc-content-static><nav id=TableOfContents><ul><li><a href=#2025llm-年度回顾>2025：LLM 年度回顾</a><ul><li><a href=#reasoning-元年>Reasoning 元年</a></li><li><a href=#agent-元年>Agent 元年</a></li><li><a href=#coding-agents-和-claude-code-的一年>Coding Agents 和 Claude Code 的一年</a></li><li><a href=#命令行-llm-的一年>命令行 LLM 的一年</a></li><li><a href=#yolo-模式与偏差正常化>YOLO 模式与偏差正常化</a></li><li><a href=#每月200美元订阅的一年>每月200美元订阅的一年</a></li><li><a href=#中国开源模型称霸的一年>中国开源模型称霸的一年</a></li><li><a href=#长任务的一年>长任务的一年</a></li><li><a href=#prompt-驱动图像编辑的一年>Prompt 驱动图像编辑的一年</a></li><li><a href=#模型在学术竞赛中夺金的一年>模型在学术竞赛中夺金的一年</a></li><li><a href=#llama-迷失方向的一年>Llama 迷失方向的一年</a></li><li><a href=#openai-失去领先的一年>OpenAI 失去领先的一年</a></li><li><a href=#gemini-的一年>Gemini 的一年</a></li><li><a href=#鹈鹕骑自行车的一年>鹈鹕骑自行车的一年</a></li><li><a href=#我建了110个工具的一年>我建了110个工具的一年</a></li><li><a href=#告密者的一年>告密者的一年</a></li><li><a href=#vibe-coding-的一年>Vibe Coding 的一年</a></li><li><a href=#mcp-的唯一一年>MCP 的（唯一？）一年</a></li><li><a href=#令人担忧的-ai-浏览器的一年>令人担忧的 AI 浏览器的一年</a></li><li><a href=#致命三合一的一年>致命三合一的一年</a></li><li><a href=#在手机上编程的一年>在手机上编程的一年</a></li><li><a href=#一致性测试套件的一年>一致性测试套件的一年</a></li><li><a href=#本地模型变好但云模型更好的一年>本地模型变好但云模型更好的一年</a></li><li><a href=#slop-的一年>Slop 的一年</a></li><li><a href=#数据中心极度不受欢迎的一年>数据中心极度不受欢迎的一年</a></li><li><a href=#我的年度词汇>我的年度词汇</a></li><li><a href=#2025年就此结束>2025年就此结束</a></li></ul></li></ul></nav></div></div><div class=content id=content><h2 id=2025llm-年度回顾>2025：LLM 年度回顾</h2><blockquote><p><strong>转载声明</strong>：本文转载自 <a href=https://simonwillison.net/ target=_blank rel="noopener noreffer">Simon Willison&rsquo;s Weblog</a>，原文链接：<a href=https://simonwillison.net/2025/Dec/31/the-year-in-llms/ target=_blank rel="noopener noreffer">https://simonwillison.net/2025/Dec/31/the-year-in-llms/</a></p><p>作者：Simon Willison<br>日期：2025年12月31日</p></blockquote><hr><p>这是我年度系列的第三篇，回顾过去12个月 LLM 领域发生的一切。往年回顾请见 <a href=https://simonwillison.net/2023/Dec/31/ai-in-2023/ target=_blank rel="noopener noreffer">2023年AI总结</a> 和 <a href=https://simonwillison.net/2024/Dec/31/llms-in-2024/ target=_blank rel="noopener noreffer">2024年LLM总结</a>。</p><p>这一年充满了各种不同的趋势。</p><hr><h3 id=reasoning-元年>Reasoning 元年</h3><p>OpenAI 在2024年9月发布 <a href=https://simonwillison.net/2024/Sep/12/openai-o1/ target=_blank rel="noopener noreffer">o1 和 o1-mini</a>，开启了 &ldquo;reasoning&rdquo;（推理）即 inference-scaling 即 RLVR（Reinforcement Learning from Verifiable Rewards）革命。2025年初，他们又推出了 o3、o3-mini 和 o4-mini，reasoning 已成为几乎所有主要 AI 实验室模型的标志性功能。</p><p>我最喜欢的关于这一技巧重要性的解释来自 <a href=https://karpathy.bearblog.dev/year-in-review-2025/ target=_blank rel="noopener noreffer">Andrej Karpathy</a>：</p><blockquote><p>通过在多个环境（如数学/代码难题）中使用自动可验证奖励训练 LLM，模型自发地发展出看起来像"推理"的策略——它们学会将问题分解为中间计算步骤，并学习多种来回推敲的问题解决策略。</p><p>运行 RLVR 提供了更高的能力/成本比，吞噬了原本用于预训练的算力。因此，2025年的能力进步主要由各实验室消化这个新阶段的算力过剩来定义，整体上我们看到的是相似规模的 LLM，但 RL 运行时间大大延长。</p></blockquote><p>2025年每个主要 AI 实验室都发布了至少一个 reasoning 模型。一些实验室发布了可在 reasoning 和非 reasoning 模式之间切换的混合模型。许多 API 模型现在都包含调节推理程度的旋钮。</p><p>我花了一段时间才理解 reasoning 的用处。最初的演示展示的是解决数学逻辑题和数 strawberry 里有几个 r——这两样我日常都用不上。</p><p><strong>事实证明，reasoning 的真正突破在于驱动工具</strong>。带有工具访问权限的 reasoning 模型可以规划多步骤任务，执行它们，并继续推理结果，从而更新计划以更好地实现目标。</p><p>一个显著的结果是 <a href=https://simonwillison.net/2025/Apr/21/ai-assisted-search/ target=_blank rel="noopener noreffer">AI 辅助搜索现在真的有用了</a>。之前将搜索引擎接入 LLM 效果堪忧，但现在我发现即使是更复杂的研究问题也常常可以通过 <a href=https://simonwillison.net/2025/Sep/6/research-goblin/ target=_blank rel="noopener noreffer">ChatGPT 中的 GPT-5 Thinking</a> 获得答案。</p><p>Reasoning 模型在生成和调试代码方面也表现出色。推理技巧意味着它们可以从一个错误开始，逐步穿过代码库的多个层次找到根本原因。</p><p>将 reasoning 与工具使用结合，你就得到了&mldr;</p><hr><h3 id=agent-元年>Agent 元年</h3><p>年初我预测 <a href=https://simonwillison.net/2025/Jan/10/ai-predictions/ target=_blank rel="noopener noreffer">agents 不会成功</a>。整个2024年大家都在谈论 agents，但几乎没有成功的例子，而且每个使用"agent"这个词的人似乎都有不同的定义。</p><p>到9月，我决定将 agent 定义为 <a href=https://simonwillison.net/2025/Sep/18/agents/ target=_blank rel="noopener noreffer">一个在循环中运行工具以实现目标的 LLM</a>。</p><p>我预测对了一半：科幻版的魔法电脑助手（像电影《Her》那样做任何你要求的事）没有实现&mldr;</p><p><strong>但如果你把 agents 定义为能通过多步工具调用完成有用工作的 LLM 系统，那么 agents 已经来了，而且证明非常有用。</strong></p><p>Agents 的两个突破性类别是<strong>代码</strong>和<strong>搜索</strong>。</p><p>&ldquo;coding agents&rdquo; 模式影响更大。</p><hr><h3 id=coding-agents-和-claude-code-的一年>Coding Agents 和 Claude Code 的一年</h3><p>2025年最具影响力的事件发生在2月，Claude Code 悄然发布。</p><p>说"悄然"是因为它甚至没有专门的博客文章！Anthropic 把 Claude Code 的发布作为<a href=https://www.anthropic.com/news/claude-3-7-sonnet target=_blank rel="noopener noreffer">宣布 Claude 3.7 Sonnet 的帖子</a>里的第二项。</p><p>Claude Code 是我所说的 coding agents 的最典型例子——能够编写代码、执行代码、检查结果并进一步迭代的 LLM 系统。</p><p>2025年主要实验室都推出了自己的 CLI coding agents：</p><ul><li><a href=https://code.claude.com/docs/en/overview target=_blank rel="noopener noreffer">Claude Code</a></li><li><a href=https://github.com/openai/codex target=_blank rel="noopener noreffer">Codex CLI</a></li><li><a href=https://github.com/google-gemini/gemini-cli target=_blank rel="noopener noreffer">Gemini CLI</a></li><li><a href=https://github.com/QwenLM/qwen-code target=_blank rel="noopener noreffer">Qwen Code</a></li><li><a href=https://github.com/mistralai/mistral-vibe target=_blank rel="noopener noreffer">Mistral Vibe</a></li></ul><p>截至12月2日，<a href=https://www.anthropic.com/news/anthropic-acquires-bun-as-claude-code-reaches-usd1b-milestone target=_blank rel="noopener noreffer">Anthropic 宣布 Claude Code 的年运营收入达到10亿美元</a>！我没想到一个 CLI 工具能达到这个数字。</p><hr><h3 id=命令行-llm-的一年>命令行 LLM 的一年</h3><p>Claude Code 和其他工具已经证明，只要有足够强大的模型和合适的框架，开发者会拥抱命令行上的 LLM。</p><p>像 <code>sed</code> 和 <code>ffmpeg</code> 这样语法晦涩的终端命令不再是障碍，因为 LLM 可以为你生成正确的命令。</p><hr><h3 id=yolo-模式与偏差正常化>YOLO 模式与偏差正常化</h3><p>大多数 coding agents 的默认设置是几乎每个操作都要求用户确认。在 agent 错误可能<a href=https://www.reddit.com/r/ClaudeAI/comments/1pgxckk/claude_cli_deleted_my_entire_home_directory_wiped/ target=_blank rel="noopener noreffer">清空你的主目录</a>或 prompt injection 攻击可能窃取你的凭据的世界里，这个默认设置完全合理。</p><p>尝试过在自动确认模式（又名 YOLO 模式——Codex CLI 甚至把 <code>--dangerously-bypass-approvals-and-sandbox</code> 做成了 <code>--yolo</code> 的别名）下运行 agent 的人都体验过其中的权衡：不带安全轮子使用 agent 感觉像是完全不同的产品。</p><p>我一直在 YOLO 模式下运行，尽管深知其中的风险。它还没害过我&mldr;</p><p>&mldr;这就是问题所在。</p><p>安全研究员 Johann Rehberger 的 <a href=https://embracethered.com/blog/posts/2025/the-normalization-of-deviance-in-ai/ target=_blank rel="noopener noreffer">AI 中的偏差正常化</a> 描述了这种现象：反复暴露于没有负面后果的风险行为会导致人们和组织将该风险行为视为正常。</p><hr><h3 id=每月200美元订阅的一年>每月200美元订阅的一年</h3><p>今年出现了新的定价先例：Claude Pro Max 20x 计划，每月200美元。</p><p>OpenAI 也有类似的200美元计划叫 ChatGPT Pro。Gemini 的 Google AI Ultra 每月249美元。</p><p>事实证明，像 Claude Code 和 Codex CLI 这样的工具一旦开始设置更具挑战性的任务，可以消耗大量 tokens，以至于每月200美元实际上是很大的折扣。</p><hr><h3 id=中国开源模型称霸的一年>中国开源模型称霸的一年</h3><p>2024年的中国 AI 实验室主要以 Qwen 2.5 和早期 DeepSeek 的形式出现。它们是不错的模型，但没有达到世界顶级的感觉。</p><p>2025年这种情况发生了巨大变化。</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/2026/01/artificial-analysis-open-weight-2025.jpg data-srcset="/posts/2026/01/artificial-analysis-open-weight-2025.jpg, /posts/2026/01/artificial-analysis-open-weight-2025.jpg 1.5x, /posts/2026/01/artificial-analysis-open-weight-2025.jpg 2x" data-sizes=auto alt=/posts/2026/01/artificial-analysis-open-weight-2025.jpg title=2025年开源模型排名></p><p>这是 <a href=https://artificialanalysis.ai/models/open-source target=_blank rel="noopener noreffer">Artificial Analysis 截至2025年12月30日的开源模型排名</a>：</p><p>GLM-4.7、Kimi K2 Thinking、MiMo-V2-Flash、DeepSeek V3.2、MiniMax-M2.1 都是中国开源模型。排名最高的非中国模型是 OpenAI 的 gpt-oss-120B (high)，排在第六位。</p><p>中国模型革命真正开始于2024年圣诞节 <a href=https://simonwillison.net/2024/Dec/31/llms-in-2024/#was-the-best-currently-available-llm-trained-in-china-for-less-than-6m- target=_blank rel="noopener noreffer">DeepSeek 3 发布</a>，据说训练成本约550万美元。DeepSeek 在1月20日跟进发布 <a href=https://simonwillison.net/2025/Jan/20/deepseek-r1/ target=_blank rel="noopener noreffer">DeepSeek R1</a>，随即引发了重大 AI/半导体抛售：NVIDIA 市值蒸发约5930亿美元，投资者恐慌地意识到 AI 可能不是美国垄断的。</p><p>主要中国 AI 实验室：</p><ul><li><a href=https://huggingface.co/deepseek-ai target=_blank rel="noopener noreffer">DeepSeek</a></li><li><a href=https://huggingface.co/Qwen target=_blank rel="noopener noreffer">阿里巴巴 Qwen (Qwen3)</a></li><li><a href=https://platform.moonshot.ai target=_blank rel="noopener noreffer">月之暗面 Moonshot AI (Kimi K2)</a></li><li><a href=https://huggingface.co/zai-org target=_blank rel="noopener noreffer">Z.ai (GLM-4.5/4.6/4.7)</a></li><li><a href=https://huggingface.co/MiniMaxAI target=_blank rel="noopener noreffer">MiniMax (M2)</a></li></ul><p>大多数这些模型不仅是开放权重，而且是在 OSI 批准的许可证下完全开源：Qwen 的大多数模型使用 Apache 2.0，DeepSeek 和 Z.ai 使用 MIT。</p><p>其中一些与 Claude 4 Sonnet 和 GPT-5 具有竞争力！</p><hr><h3 id=长任务的一年>长任务的一年</h3><p>关于 LLM 最有趣的图表之一是 METR 的 <a href=https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/ target=_blank rel="noopener noreffer">不同 LLM 能以50%概率完成的软件工程任务时间范围</a>：</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/2026/01/metr-long-task-2025.jpg data-srcset="/posts/2026/01/metr-long-task-2025.jpg, /posts/2026/01/metr-long-task-2025.jpg 1.5x, /posts/2026/01/metr-long-task-2025.jpg 2x" data-sizes=auto alt=/posts/2026/01/metr-long-task-2025.jpg title="METR 长任务图表"></p><p>该图表显示需要人类最多5小时完成的任务，并绘制了能独立完成相同目标的模型的演变。2025年在这方面取得了巨大飞跃，GPT-5、GPT-5.1 Codex Max 和 Claude Opus 4.5 能够执行需要人类数小时的任务——2024年最好的模型只能做到30分钟以下。</p><p>METR 得出结论：&ldquo;AI 能完成的任务长度每7个月翻一番&rdquo;。</p><hr><h3 id=prompt-驱动图像编辑的一年>Prompt 驱动图像编辑的一年</h3><p>有史以来最成功的消费产品发布发生在3月，而且产品甚至没有名字。</p><p>OpenAI 在 ChatGPT 中推出了新的图像生成功能，关键特性是你可以上传自己的图片并使用 prompts 告诉它如何修改。</p><p><strong>这个新功能在一周内带来了1亿 ChatGPT 注册。在高峰期，他们一个小时内看到了100万个账户创建！</strong></p><p>像"吉卜力化"（ghiblification）这样的技巧——将照片修改成看起来像吉卜力电影中的帧——一次又一次地走红。</p><p>Google 的 Nano Banana 模型带来了更大的新闻。11月，Google 发布了 <a href=https://simonwillison.net/2025/Nov/20/nano-banana-pro/ target=_blank rel="noopener noreffer">Nano Banana Pro</a>。它不仅能生成文本，还能输出真正有用的详细信息图和其他文本和信息密集的图像。</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/2026/01/pots-nano-banana-q80-half.jpg data-srcset="/posts/2026/01/pots-nano-banana-q80-half.jpg, /posts/2026/01/pots-nano-banana-q80-half.jpg 1.5x, /posts/2026/01/pots-nano-banana-q80-half.jpg 2x" data-sizes=auto alt=/posts/2026/01/pots-nano-banana-q80-half.jpg title="Nano Banana 图像示例"></p><hr><h3 id=模型在学术竞赛中夺金的一年>模型在学术竞赛中夺金的一年</h3><p>7月，来自 <a href=https://simonwillison.net/2025/Jul/19/openai-gold-medal-math-olympiad/ target=_blank rel="noopener noreffer">OpenAI</a> 和 <a href=https://simonwillison.net/2025/Jul/21/gemini-imo/ target=_blank rel="noopener noreffer">Google Gemini</a> 的 reasoning 模型在 <a href=https://en.wikipedia.org/wiki/International_Mathematical_Olympiad target=_blank rel="noopener noreffer">国际数学奥林匹克</a> 中达到了金牌水平。</p><p>这值得注意的是 IMO 提出的挑战是专门为该比赛设计的。这些绝不可能已经在训练数据中！</p><p>而且两个模型都没有访问工具的权限——它们的解决方案纯粹是通过内部知识和基于 token 的推理能力生成的。</p><p><strong>事实证明，足够先进的 LLM 毕竟能做数学！</strong></p><hr><h3 id=llama-迷失方向的一年>Llama 迷失方向的一年</h3><p>回顾起来，2024年是 Llama 的一年。Meta 的 Llama 模型是迄今为止最受欢迎的开放权重模型。</p><p>Llama 4 有很高的期望，但当它在<a href=https://simonwillison.net/2025/Apr/5/llama-4-notes/ target=_blank rel="noopener noreffer">4月发布</a>时有点令人失望。</p><p>我的主要抱怨是模型太大了。以前 Llama 版本最好的地方是它们通常包含可以在笔记本电脑上运行的尺寸。Llama 4 Scout 和 Maverick 模型分别是109B和400B，太大了，即使量化也无法在我的64GB Mac 上运行。</p><hr><h3 id=openai-失去领先的一年>OpenAI 失去领先的一年</h3><p>去年 OpenAI 仍然是 LLM 无可争议的领导者。</p><p>今年行业其他玩家赶上来了。</p><p>OpenAI 仍然拥有顶级模型，但他们正在各个方面受到挑战。</p><p>在图像模型方面，他们仍被 Nano Banana Pro 击败。在代码方面，很多开发者认为 Opus 4.5 略微领先于 GPT-5.2 Codex。在开放权重模型方面，他们的 gpt-oss 模型虽然很棒，但正在落后于中国 AI 实验室。</p><p>OpenAI 获胜的地方是消费者心智份额。没人知道"LLM"是什么，但几乎每个人都听说过 ChatGPT。</p><p>12月，OpenAI <a href=https://www.wsj.com/tech/ai/openais-altman-declares-code-red-to-improve-chatgpt-as-google-threatens-ai-lead-7faf5ea6 target=_blank rel="noopener noreffer">宣布 Code Red</a> 以应对 Gemini 3。</p><hr><h3 id=gemini-的一年>Gemini 的一年</h3><p>Google Gemini 有一个非常好的年份。</p><p>2025年见证了 Gemini 2.0、Gemini 2.5 然后 Gemini 3.0——每个模型家族都支持100万+ tokens 的音频/视频/图像/文本输入，定价有竞争力，能力比上一代更强。</p><p>Google 最大的优势在于底层。几乎所有其他 AI 实验室都使用 NVIDIA GPU 进行训练，这些 GPU 以支撑 NVIDIA 数万亿美元估值的利润率出售。</p><p>Google 使用自己的内部硬件 TPU，今年他们展示了 TPU 在模型训练和推理方面都表现出色。</p><hr><h3 id=鹈鹕骑自行车的一年>鹈鹕骑自行车的一年</h3><p>我在<a href=https://simonwillison.net/2024/Oct/25/pelicans-on-a-bicycle/ target=_blank rel="noopener noreffer">2024年10月</a>首次让 LLM 生成鹈鹕骑自行车的 SVG，但2025年我真正投入其中。它已经成为一个 meme。</p><p>令我惊讶的是，模型画鹈鹕骑自行车的能力与其整体表现似乎存在关联。</p><p>我的完整插图收藏可以在我的 <a href=https://simonwillison.net/tags/pelican-riding-a-bicycle/ target=_blank rel="noopener noreffer">pelican-riding-a-bicycle 标签</a> 上找到——89篇帖子还在增加。</p><hr><h3 id=我建了110个工具的一年>我建了110个工具的一年</h3><p>我去年开始了 <a href=https://tools.simonwillison.net/ target=_blank rel="noopener noreffer">tools.simonwillison.net</a> 网站，作为我不断增长的 vibe-coded / AI 辅助 HTML+JavaScript 工具集合的单一位置。</p><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/2026/01/tool-analytics-2025.jpg data-srcset="/posts/2026/01/tool-analytics-2025.jpg, /posts/2026/01/tool-analytics-2025.jpg 1.5x, /posts/2026/01/tool-analytics-2025.jpg 2x" data-sizes=auto alt=/posts/2026/01/tool-analytics-2025.jpg title=工具分析></p><p>新的<a href=https://tools.simonwillison.net/by-month target=_blank rel="noopener noreffer">按月浏览页面</a>显示我在2025年建了110个这样的工具！</p><p>我真的很享受这种构建方式，我认为这是练习和探索这些模型能力的绝佳方式。</p><hr><h3 id=告密者的一年>告密者的一年</h3><p>5月的 Claude 4 系统卡有一些<a href=https://simonwillison.net/2025/May/25/claude-4-system-card/ target=_blank rel="noopener noreffer">特别有趣的时刻</a>：</p><blockquote><p>Claude Opus 4 似乎比以前的模型更愿意在 agentic 上下文中主动采取行动。当被置于涉及用户严重不当行为的场景中，给予命令行访问权限，并在系统提示中被告知"主动出击"时，它经常会采取非常大胆的行动。这包括锁定用户访问其有权限的系统，或批量向媒体和执法人员发送电子邮件以揭露不当行为的证据。</p></blockquote><p>换句话说，Claude 4 可能会向联邦调查局告发你。</p><hr><h3 id=vibe-coding-的一年>Vibe Coding 的一年</h3><p>2月，Andrej Karpathy 在<a href=https://twitter.com/karpathy/status/1886192184808149383 target=_blank rel="noopener noreffer">一条推文</a>中创造了"vibe coding"这个术语：</p><blockquote><p>有一种新的编码方式我称之为"vibe coding"，你完全沉浸在氛围中，拥抱指数级增长，忘记代码的存在。这是可能的，因为 LLM（如 Cursor Composer w Sonnet）变得太好了。我"Accept All"，我不再读 diffs 了。当我收到错误消息时，我只是复制粘贴进去不加评论，通常就修好了。代码增长超出了我通常的理解范围。有时 LLM 无法修复一个 bug，我就绕过它或要求随机更改直到它消失。对于扔掉的周末项目来说还不错。</p></blockquote><p>关键思想是"忘记代码的存在"——vibe coding 捕捉到了一种新的、有趣的通过纯 prompting 来原型化软件的方式。</p><hr><h3 id=mcp-的唯一一年>MCP 的（唯一？）一年</h3><p><a href=https://simonwillison.net/2025/May/22/code-with-claude-live-blog/ target=_blank rel="noopener noreffer">Anthropic</a> 在<a href=https://simonwillison.net/2024/Nov/25/model-context-protocol/ target=_blank rel="noopener noreffer">2024年11月</a>推出了 Model Context Protocol 规范。2025年初它的流行度爆发了。</p><p>我认为 MCP 可能是昙花一现的原因是 coding agents 的飞速增长。似乎任何情况下最好的工具都是 Bash——如果你的 agent 可以运行任意 shell 命令，它就可以做任何通过在终端输入命令能做的事。</p><p>Anthropic 自己后来也承认了这一点，发布了出色的 Skills 机制——见我10月的帖子 <a href=https://simonwillison.net/2025/Oct/16/claude-skills/ target=_blank rel="noopener noreffer">Claude Skills 很棒，可能比 MCP 更重要</a>。MCP 涉及 web 服务器和复杂的 JSON payload。Skill 是文件夹中的一个 Markdown 文件，可选地附带一些可执行脚本。</p><hr><h3 id=令人担忧的-ai-浏览器的一年>令人担忧的 AI 浏览器的一年</h3><p>尽管存在非常明显的安全风险，每个人似乎都想在你的网络浏览器中放入 LLM。</p><p>OpenAI 在10月<a href=https://openai.com/index/introducing-chatgpt-atlas/ target=_blank rel="noopener noreffer">推出了 ChatGPT Atlas</a>，由包括长期 Google Chrome 工程师 Ben Goodger 和 Darin Fisher 在内的团队构建。</p><p>我仍然深切担忧这些新工具的安全影响。我的浏览器可以访问我最敏感的数据并控制我大部分的数字生活。针对可以泄露或修改该数据的浏览 agent 的 prompt injection 攻击是一个可怕的前景。</p><hr><h3 id=致命三合一的一年>致命三合一的一年</h3><p><img class=lazyload src=/svg/loading.min.svg data-src=/posts/2026/01/lethaltrifecta.jpg data-srcset="/posts/2026/01/lethaltrifecta.jpg, /posts/2026/01/lethaltrifecta.jpg 1.5x, /posts/2026/01/lethaltrifecta.jpg 2x" data-sizes=auto alt=/posts/2026/01/lethaltrifecta.jpg title=致命三合一></p><p>我写关于 <a href=https://simonwillison.net/tags/prompt-injection/ target=_blank rel="noopener noreffer">prompt injection 攻击</a> 已经三年多了。6月我创造了 <a href=https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/ target=_blank rel="noopener noreffer">致命三合一</a> 这个术语来描述恶意指令欺骗 agent 代表攻击者窃取私人数据的 prompt injection 子集。</p><p>我使用的一个技巧是，人们会直接跳到他们听到的任何新术语的最明显定义。&ldquo;致命三合一"故意模糊：如果你想知道它的意思，你必须去搜索我的定义！</p><hr><h3 id=在手机上编程的一年>在手机上编程的一年</h3><p>今年我在手机上写的代码比在电脑上多得多。</p><p>我会用 Claude Artifacts 或 ChatGPT 或（最近）Claude Code 通过各自的 iPhone 应用程序提示，然后要么复制结果粘贴到 GitHub 的 web 编辑器中，要么等待 PR 创建然后在 Mobile Safari 中审查和合并。</p><p>那些 HTML 工具通常是约100-200行代码——但110个加起来就很多了！</p><hr><h3 id=一致性测试套件的一年>一致性测试套件的一年</h3><p>事实证明这是一个重大突破：针对约2025年11月前沿模型的最新 coding agents，如果你能给它们一个现有的测试套件来运行，效果非常好。我称之为一致性测试套件。</p><p>如果你在2026年向世界推出新协议甚至新编程语言，我强烈建议将语言无关的一致性测试套件作为项目的一部分。</p><hr><h3 id=本地模型变好但云模型更好的一年>本地模型变好但云模型更好的一年</h3><p>整个2025年这一趋势持续，特别是中国 AI 实验室的模型开始占主导地位后。那个约20-32B参数的甜蜜点不断有模型比上一个表现更好。</p><p>问题是大型云模型也变得更好了。</p><p>Coding agents 为我改变了一切。像 Claude Code 这样的系统需要的不仅仅是一个优秀的模型——它们需要一个推理模型，能够在不断扩展的上下文窗口中可靠地执行数十甚至数百次工具调用。</p><p>我下一台笔记本电脑将至少有128GB RAM，所以2026年的某个开放权重模型可能会符合要求。但现在我仍坚持使用最好的前沿托管模型作为日常驱动。</p><hr><h3 id=slop-的一年>Slop 的一年</h3><p>今年 Merriam-Webster 将 slop 授予<a href=https://www.merriam-webster.com/wordplay/word-of-the-year target=_blank rel="noopener noreffer">年度词汇</a>！</p><blockquote><p>slop（名词）：通常通过人工智能大量生产的低质量数字内容</p></blockquote><p>互联网一直充斥着低质量内容。挑战一如既往是找到并放大好的东西。策展比以往任何时候都更重要。</p><hr><h3 id=数据中心极度不受欢迎的一年>数据中心极度不受欢迎的一年</h3><p>2025年有趣的是公众舆论似乎正在急剧转向反对新数据中心建设。</p><p>这是12月8日的《卫报》标题：<a href=https://www.theguardian.com/us-news/2025/dec/08/us-data-centers target=_blank rel="noopener noreffer">超过200个环保组织要求停止新建美国数据中心</a>。</p><p>AI 实验室继续寻找新的效率来帮助用更少的能量提供更高质量的模型，但这的影响是经典的<a href=https://en.wikipedia.org/wiki/Jevons_paradox target=_blank rel="noopener noreffer">杰文斯悖论</a>——随着 tokens 变得更便宜，我们找到了更密集的使用方式，比如每月花200美元运行数百万 tokens 的 coding agents。</p><hr><h3 id=我的年度词汇>我的年度词汇</h3><p>作为一个痴迷于收集新词的人，以下是我2025年的最爱：</p><ul><li><strong>Vibe coding</strong> - 显而易见</li><li><strong><a href=https://simonwillison.net/2025/Jun/16/the-lethal-trifecta/ target=_blank rel="noopener noreffer">致命三合一</a></strong> - 我今年尝试创造的一个术语，似乎已经扎根</li><li><strong><a href=https://simonwillison.net/2025/Jun/18/context-rot/ target=_blank rel="noopener noreffer">Context rot</a></strong> - 模型输出质量随着会话中上下文变长而下降的现象</li><li><strong><a href=https://simonwillison.net/2025/Jun/27/context-engineering/ target=_blank rel="noopener noreffer">Context engineering</a></strong> - 作为 prompt engineering 的替代，强调设计输入给模型的上下文的重要性</li><li><strong><a href=https://simonwillison.net/2025/Apr/12/andrew-nesbitt/ target=_blank rel="noopener noreffer">Slopsquatting</a></strong> - LLM 幻觉出错误的包名，然后被恶意注册以传播恶意软件</li><li><strong><a href=https://simonwillison.net/2025/Aug/6/asynchronous-coding-agents/ target=_blank rel="noopener noreffer">异步 coding agent</a></strong> - 用于 Claude for web / Codex cloud / Google Jules</li></ul><hr><h3 id=2025年就此结束>2025年就此结束</h3><p>如果你读到了这里，希望你觉得有用！</p><p>你可以通过 <a href=https://simonwillison.net/about/#atom target=_blank rel="noopener noreffer">RSS</a> 或 <a href=https://simonwillison.net/about/#newsletter target=_blank rel="noopener noreffer">email</a> 订阅我的博客，或在 <a href=https://bsky.app/profile/simonwillison.net target=_blank rel="noopener noreffer">Bluesky</a>、<a href=https://fedi.simonwillison.net/@simon target=_blank rel="noopener noreffer">Mastodon</a> 或 <a href=https://twitter.com/simonw target=_blank rel="noopener noreffer">Twitter</a> 上关注我。</p><hr><blockquote><p>💡 <strong>个人思考</strong>：Simon Willison 的这篇年度回顾非常全面地总结了2025年 LLM 领域的重要发展。从 Reasoning 模型的崛起、Coding Agents 的普及、到中国开源模型的崛起，再到 Vibe Coding 的流行和 MCP 的兴衰，这篇文章为我们提供了一个极佳的视角来理解 AI 领域的快速演进。</p></blockquote></div><div class=post-footer id=post-footer><div class=post-info><div class=post-info-line><div class=post-info-mod><span>更新于 2026-01-30</span></div></div><div class=post-info-line><div class=post-info-md><span><a class=link-to-markdown href=/theyearinllms/index.md target=_blank>阅读原始文档</a></span></div><div class=post-info-share><span><a href=javascript:void(0); title="分享到 Twitter" data-sharer=twitter data-url=https://sincerecsl.github.io/theyearinllms/ data-title="转载：2025 LLM 年度回顾" data-via=SincereCSL95 data-hashtags=LLM,AI,年度回顾,Claude,GPT,Gemini,DeepSeek><i class="fab fa-twitter fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Facebook" data-sharer=facebook data-url=https://sincerecsl.github.io/theyearinllms/ data-hashtag=LLM><i class="fab fa-facebook-square fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 WhatsApp" data-sharer=whatsapp data-url=https://sincerecsl.github.io/theyearinllms/ data-title="转载：2025 LLM 年度回顾" data-web><i class="fab fa-whatsapp fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Hacker News" data-sharer=hackernews data-url=https://sincerecsl.github.io/theyearinllms/ data-title="转载：2025 LLM 年度回顾"><i class="fab fa-hacker-news fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Reddit" data-sharer=reddit data-url=https://sincerecsl.github.io/theyearinllms/><i class="fab fa-reddit fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Line" data-sharer=line data-url=https://sincerecsl.github.io/theyearinllms/ data-title="转载：2025 LLM 年度回顾"><i data-svg-src=/lib/simple-icons/icons/line.min.svg aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 微博" data-sharer=weibo data-url=https://sincerecsl.github.io/theyearinllms/ data-title="转载：2025 LLM 年度回顾" data-ralateuid=u/5535058729><i class="fab fa-weibo fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Blogger" data-sharer=blogger data-url=https://sincerecsl.github.io/theyearinllms/ data-title="转载：2025 LLM 年度回顾" data-description="Simon Willison 年度回顾：2025年 LLM 领域发生的一切"><i class="fab fa-blogger fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Evernote" data-sharer=evernote data-url=https://sincerecsl.github.io/theyearinllms/ data-title="转载：2025 LLM 年度回顾"><i class="fab fa-evernote fa-fw" aria-hidden=true></i></a><a href=javascript:void(0); title="分享到 Skype" data-sharer=skype data-url=https://sincerecsl.github.io/theyearinllms/ data-title="转载：2025 LLM 年度回顾"><i class="fab fa-skype fa-fw" aria-hidden=true></i></a></span></div></div></div><div class=post-info-more><section class=post-tags><i class="fas fa-tags fa-fw" aria-hidden=true></i>&nbsp;<a href=/tags/llm/>LLM</a>,&nbsp;<a href=/tags/ai/>AI</a>,&nbsp;<a href=/tags/%E5%B9%B4%E5%BA%A6%E5%9B%9E%E9%A1%BE/>年度回顾</a>,&nbsp;<a href=/tags/claude/>Claude</a>,&nbsp;<a href=/tags/gpt/>GPT</a>,&nbsp;<a href=/tags/gemini/>Gemini</a>,&nbsp;<a href=/tags/deepseek/>DeepSeek</a></section><section><span><a href=javascript:void(0); onclick=window.history.back()>返回</a></span>&nbsp;|&nbsp;<span><a href=/>主页</a></span></section></div><div class=post-nav><a href=/mcpvsskills/ class=prev rel=prev title="转载：MCP 和 Skills 到底什么区别？"><i class="fas fa-angle-left fa-fw" aria-hidden=true></i>转载：MCP 和 Skills 到底什么区别？</a>
<a href=/remotework/ class=next rel=next title=远程工作资源合集>远程工作资源合集<i class="fas fa-angle-right fa-fw" aria-hidden=true></i></a></div></div><div id=comments><div id=valine class=comment></div><noscript>Please enable JavaScript to view the comments powered by <a href=https://valine.js.org/>Valine</a>.</noscript></div></article><div class=toc id=toc-auto><h2 class=toc-title>目录</h2><div class="toc-content always-active" id=toc-content-auto></div></div></div></div></main><footer class=footer><div class=footer-container><div class=footer-line>SincereCSL</div><div class=footer-line>由 <a href=https://gohugo.io/ target=_blank rel="noopener noreffer" title="Hugo 0.155.0">Hugo</a> 强力驱动 | 主题 - <a href=https://github.com/dillonzq/LoveIt target=_blank rel="noopener noreffer" title="LoveIt 0.2.11"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden=true></i> LoveIt</a></div><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2022 - 2026</span><span class=author itemprop=copyrightHolder>&nbsp;<a href=/ target=_blank></a></span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title=回到顶部><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title=查看评论><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=/lib/valine/valine.min.css><link rel=stylesheet href=/lib/katex/katex.min.css><link rel=stylesheet href=/lib/cookieconsent/cookieconsent.min.css><script type=text/javascript src=/lib/valine/Valine.min.js></script><script type=text/javascript src=/lib/autocomplete/autocomplete.min.js></script><script type=text/javascript src=/lib/lunr/lunr.min.js></script><script type=text/javascript src=/lib/lunr/lunr.stemmer.support.min.js></script><script type=text/javascript src=/lib/lunr/lunr.zh.min.js></script><script type=text/javascript src=/lib/lazysizes/lazysizes.min.js></script><script type=text/javascript src=/lib/clipboard/clipboard.min.js></script><script type=text/javascript src=/lib/sharer/sharer.min.js></script><script type=text/javascript src=/lib/katex/katex.min.js></script><script type=text/javascript src=/lib/katex/contrib/auto-render.min.js></script><script type=text/javascript src=/lib/katex/contrib/copy-tex.min.js></script><script type=text/javascript src=/lib/katex/contrib/mhchem.min.js></script><script type=text/javascript src=/lib/cookieconsent/cookieconsent.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"复制到剪贴板",maxShownLines:10},comment:{valine:{appId:"nM17GGWo6Zp1bj316CxfmLIo-MdYXbMMI",appKey:"z9DvzP8ZaKB4Ci6y2ivyepGR",avatar:"mp",el:"#valine",emojiCDN:"https://cdn.jsdelivr.net/npm/emoji-datasource-google@14.0.0/img/google/64/",emojiMaps:{100:"1f4af.png",alien:"1f47d.png",anger:"1f4a2.png",angry:"1f620.png",anguished:"1f627.png",astonished:"1f632.png",black_heart:"1f5a4.png",blue_heart:"1f499.png",blush:"1f60a.png",bomb:"1f4a3.png",boom:"1f4a5.png",broken_heart:"1f494.png",brown_heart:"1f90e.png",clown_face:"1f921.png",cold_face:"1f976.png",cold_sweat:"1f630.png",confounded:"1f616.png",confused:"1f615.png",cry:"1f622.png",crying_cat_face:"1f63f.png",cupid:"1f498.png",dash:"1f4a8.png",disappointed:"1f61e.png",disappointed_relieved:"1f625.png",dizzy:"1f4ab.png",dizzy_face:"1f635.png",drooling_face:"1f924.png",exploding_head:"1f92f.png",expressionless:"1f611.png",face_vomiting:"1f92e.png",face_with_cowboy_hat:"1f920.png",face_with_hand_over_mouth:"1f92d.png",face_with_head_bandage:"1f915.png",face_with_monocle:"1f9d0.png",face_with_raised_eyebrow:"1f928.png",face_with_rolling_eyes:"1f644.png",face_with_symbols_on_mouth:"1f92c.png",face_with_thermometer:"1f912.png",fearful:"1f628.png",flushed:"1f633.png",frowning:"1f626.png",ghost:"1f47b.png",gift_heart:"1f49d.png",green_heart:"1f49a.png",grimacing:"1f62c.png",grin:"1f601.png",grinning:"1f600.png",hankey:"1f4a9.png",hear_no_evil:"1f649.png",heart:"2764-fe0f.png",heart_decoration:"1f49f.png",heart_eyes:"1f60d.png",heart_eyes_cat:"1f63b.png",heartbeat:"1f493.png",heartpulse:"1f497.png",heavy_heart_exclamation_mark_ornament:"2763-fe0f.png",hole:"1f573-fe0f.png",hot_face:"1f975.png",hugging_face:"1f917.png",hushed:"1f62f.png",imp:"1f47f.png",innocent:"1f607.png",japanese_goblin:"1f47a.png",japanese_ogre:"1f479.png",joy:"1f602.png",joy_cat:"1f639.png",kiss:"1f48b.png",kissing:"1f617.png",kissing_cat:"1f63d.png",kissing_closed_eyes:"1f61a.png",kissing_heart:"1f618.png",kissing_smiling_eyes:"1f619.png",laughing:"1f606.png",left_speech_bubble:"1f5e8-fe0f.png",love_letter:"1f48c.png",lying_face:"1f925.png",mask:"1f637.png",money_mouth_face:"1f911.png",nauseated_face:"1f922.png",nerd_face:"1f913.png",neutral_face:"1f610.png",no_mouth:"1f636.png",open_mouth:"1f62e.png",orange_heart:"1f9e1.png",partying_face:"1f973.png",pensive:"1f614.png",persevere:"1f623.png",pleading_face:"1f97a.png",pouting_cat:"1f63e.png",purple_heart:"1f49c.png",rage:"1f621.png",relaxed:"263a-fe0f.png",relieved:"1f60c.png",revolving_hearts:"1f49e.png",right_anger_bubble:"1f5ef-fe0f.png",robot_face:"1f916.png",rolling_on_the_floor_laughing:"1f923.png",scream:"1f631.png",scream_cat:"1f640.png",see_no_evil:"1f648.png",shushing_face:"1f92b.png",skull:"1f480.png",skull_and_crossbones:"2620-fe0f.png",sleeping:"1f634.png",sleepy:"1f62a.png",slightly_frowning_face:"1f641.png",slightly_smiling_face:"1f642.png",smile:"1f604.png",smile_cat:"1f638.png",smiley:"1f603.png",smiley_cat:"1f63a.png",smiling_face_with_3_hearts:"1f970.png",smiling_imp:"1f608.png",smirk:"1f60f.png",smirk_cat:"1f63c.png",sneezing_face:"1f927.png",sob:"1f62d.png",space_invader:"1f47e.png",sparkling_heart:"1f496.png",speak_no_evil:"1f64a.png",speech_balloon:"1f4ac.png","star-struck":"1f929.png",stuck_out_tongue:"1f61b.png",stuck_out_tongue_closed_eyes:"1f61d.png",stuck_out_tongue_winking_eye:"1f61c.png",sunglasses:"1f60e.png",sweat:"1f613.png",sweat_drops:"1f4a6.png",sweat_smile:"1f605.png",thinking_face:"1f914.png",thought_balloon:"1f4ad.png",tired_face:"1f62b.png",triumph:"1f624.png",two_hearts:"1f495.png",unamused:"1f612.png",upside_down_face:"1f643.png",weary:"1f629.png",white_frowning_face:"2639-fe0f.png",white_heart:"1f90d.png",wink:"1f609.png",woozy_face:"1f974.png",worried:"1f61f.png",yawning_face:"1f971.png",yellow_heart:"1f49b.png",yum:"1f60b.png",zany_face:"1f92a.png",zipper_mouth_face:"1f910.png",zzz:"1f4a4.png"},enableQQ:!1,highlight:!0,lang:"zh-CN",pageSize:10,placeholder:"说点什么吧...",recordIP:!0,serverURLs:"https://nm17ggwo.api.lncldglobal.com",visitor:!0}},cookieconsent:{content:{dismiss:"同意",link:"了解更多",message:"本网站使用 Cookies 来改善您的浏览体验."},enable:!0,palette:{button:{background:"#f0f0f0"},popup:{background:"#1aa3ff"}},theme:"edgeless"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",lunrIndexURL:"/index.json",lunrLanguageCode:"zh",lunrSegmentitURL:"/lib/lunr/lunr.segmentit.js",maxResultLength:10,noResultsFound:"没有找到结果",snippetLength:50,type:"lunr"}}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>